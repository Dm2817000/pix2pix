# pix2pix

这是一个基于 PyTorch 深度学习框架实现的 Pix2pix 条件对抗生成网络（Conditional Generative Adversarial Network, cGAN）项目。该项目旨在利用成对的图像数据集，学习图像之间的映射关系，从而实现多种图像到图像翻译任务，例如将语义分割图转换为真实图像，将线稿转化为照片，或者进行风格迁移等。

1. 数据集准备：
（1）数据集来自StyleGAN公开的FFHQ数据集，从中选取了500张亚洲人脸，使用ArcaneGAN进行了处理。数据集是成对的，因此有监督和无监督模型均可以使用。其中训练集共有400张图片，测试集共有100张。
（2）定义数据集类StyleImageDataset读取内容图像和风格图像。
（3）对数据集进行预处理，包括调整图像大小、归一化等。

2. 模型构建：
使用pix2pix网络结构，构建生成器和判别器模型。生成器将输入图像转换为风格化图像，判别器将评估生成图像的真实性。
可以选择使用U-Net结构作为生成器，使用PatchGAN作为判别器。

3. 模型训练：
（1）输入数据：输入成对的图像数据，即一个输入图像和其对应的目标图像。
（2）训练判别器：用生成图像和真实图像对判别器进行训练，使其区分真假图像。通过最小化判别器的损失，让其输出接近 1 表示真实，接近 0 表示虚假。
（3）训练生成器：在保持判别器参数不变的情况下，训练生成器使其生成的图像能够“欺骗”判别器，即判别器误认为生成的图像是真实的，同时最小化 L1 损失。
（4）迭代训练判别器和生成器，直到损失函数收敛或达到设定的训练轮数。

损失函数包含对抗性损失函数和L1损失：
Loss=GAN Loss+λ×L1 Loss，λ是一个权重系数，通常设置为100。

4. 生成图像：
使用训练好的模型对新的内容图像进行风格迁移，生成风格化图像。

5. 技术栈：
PyTorch: 深度学习框架

Torchvision: 图像数据集和变换

NumPy: 数值计算

PIL (Pillow): 图像处理

Matplotlib: 图像可视化

tqdm: 进度条显示

glob: 文件路径查找
